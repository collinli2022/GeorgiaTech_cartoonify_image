# -*- coding: utf-8 -*-
"""cartoonifying-image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gqNaXqs_KWorqkKXalO6gIqEmB2LVk5O

# Cartoonify a Image
Collin Li

06/14/2021
"""

# imports
import cv2 # for image processing
from google.colab.patches import cv2_imshow
import numpy as np # to store image
import matplotlib.pyplot as plt
import sys
import requests

# input a image path and it will output a cartoonified image
def cartoonify(path, resize_shape=(960,540)):
    orig = cv2.imread(path) # get image
    # orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) # convert it to color we view it (commented out since I am using cv2 to show images) 
    if orig is None:
        print("Path incorrect, no image found")
        sys.exit()

    ## Original ##
    ## Resize to 320, 180 ##
    sized = cv2.resize(orig, resize_shape)
    ## Plot ##
    #cv2_imshow(sized)

    ## Grayscale (to improve smoothing) ##
    grayScaleImage = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY) # grayscale for better smoothing
    sized = cv2.resize(grayScaleImage, resize_shape)
    ## Plot ##
    #cv2_imshow(sized)

    ## MedianBlur (to improve edge detection) ##
    smoothGrayScale = cv2.medianBlur(grayScaleImage, 7) #  smooth image for better edge detection
    sized = cv2.resize(smoothGrayScale, resize_shape)
    ## Plot ##
    #cv2_imshow(sized)

    ## Adaptive Edge Threshold ##
    getEdge = cv2.adaptiveThreshold(smoothGrayScale, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 4) # get edges
    sized = cv2.resize(getEdge, resize_shape)
    ## Plot ##
    #cv2_imshow(sized)

    ## Color Filter ##
    colorImage = cv2.bilateralFilter(orig, 9, 300, 300) # filter color
    sized = cv2.resize(colorImage, resize_shape)
    ## Plot ##
    #cv2_imshow(sized)

    ## Boolean ##
    cartoonImage = cv2.bitwise_and(colorImage, colorImage, mask=getEdge) # combind image and edges
    sized = cv2.resize(cartoonImage, resize_shape)
    ## Plot ##
    cv2_imshow(sized)

# input a image path and it will output a cartoonified image
def better_cartoonify(path, numDownSamples = 2, numBilateralFilters = 50, resize_shape=(1920,1080)):

    ## Get image ##
    orig = cv2.imread(path) 
    orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
    images = {} 
    # orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) # convert it to color we view it (commented out since I am using cv2 to show images) 
    if orig is None:
        print("Path incorrect, no image found")
        sys.exit()

    ## Original ##
    ## Resize to resize_shape ##
    images['orig1'] = cv2.resize(orig, resize_shape)
    images['orig2'] = cv2.resize(orig, resize_shape)

    ## downsample image using Gaussian pyramid ##
    for _ in range(numDownSamples): 
      orig = cv2.pyrDown(orig)
    images['downsample'] = cv2.resize(orig, resize_shape)

    ## repeatedly apply small bilateral filter instead of applying ##
    ## one large filter ##
    for _ in range(numBilateralFilters): 
      orig = cv2.bilateralFilter(orig, 9, 9, 7)
    images['bilateral'] = cv2.resize(orig, resize_shape)

    #cv2.imshow("bilateral filter",img_color) 
    #cv2.waitKey(0) 
    # upsample image to original size 
    for _ in range(numDownSamples): 
      orig = cv2.pyrUp(orig)
    images['upsample'] = cv2.resize(orig, resize_shape)

    ## MedianBlur for even more blur ##
    orig = cv2.medianBlur(orig, 9)
    orig = cv2.medianBlur(orig, 9)
    images['blur'] = cv2.resize(orig, resize_shape)

    ## Grayscale (to improve smoothing) ##
    grayScaleImage = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)
    images['grayscale'] = cv2.resize(grayScaleImage, resize_shape)

    ## Adaptive Edge Threshold ## # TODO: thinner edges and greater threshold 
    getEdge = cv2.adaptiveThreshold(grayScaleImage, 255, 
                                    cv2.ADAPTIVE_THRESH_MEAN_C, 
                                    cv2.THRESH_BINARY, 9, 2) # TODO: increase threshold
    images['edge'] = cv2.resize(getEdge, resize_shape)

    ## Color Filter ##
    colorImage = cv2.bilateralFilter(orig, 9, 300, 300) # filter color
    images['color filter'] = cv2.resize(colorImage, resize_shape)

    ## Combined ##
    cartoonImage = cv2.bitwise_and(colorImage, colorImage, mask=getEdge) # combind image and edges
    images['combined'] = cv2.resize(cartoonImage, resize_shape)

    ## Plot images and steps ## 
    fig, axes = plt.subplots(5,2, figsize=(25,25), subplot_kw={'xticks':[], 'yticks':[]}, gridspec_kw=dict(hspace=0.1, wspace=0.1))
    keys = []
    ## keys into list ##
    for key in images.keys():
        keys.append(key)

    for i, ax in enumerate(axes.flat):
      ax.imshow(images[keys[i]], cmap='gray')
      ax.title.set_text(keys[i])
    plt.show()

## get image online ##
#response = requests.get("https://api.time.com/wp-content/uploads/2015/12/star-wars-episode-iii-revenge-of-the-sith-obi-wan.jpg")
response = requests.get("https://images.immediate.co.uk/production/volatile/sites/4/2020/12/dino-80bbd77.jpg?quality=90&resize=768,574")

## open image and save locally ##
file = open("sample_image.png", "wb")
file.write(response.content)
file.close()

## test method ##
# cartoonify('/content/sample_image.png')
better_cartoonify('/content/sample_image.png')